{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Longevity Evidence Agent - Google Colab\n",
    "\n",
    "This notebook runs the entire pipeline in Google Colab (free GPU tier).\n",
    "\n",
    "**Before running:**\n",
    "1. Get Reddit API credentials from https://www.reddit.com/prefs/apps\n",
    "2. Fill in the credentials in Cell 2\n",
    "3. Run all cells (Runtime → Run all)\n",
    "4. Download results when complete\n",
    "\n",
    "**Expected runtime:** ~60-90 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/yourname/longevity-reddit-agent.git\n",
    "%cd longevity-reddit-agent\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q praw pandas requests python-dotenv pyarrow ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Credentials\n",
    "\n",
    "**IMPORTANT:** Replace these with your actual Reddit API credentials!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Reddit API credentials\n",
    "os.environ[\"REDDIT_CLIENT_ID\"] = \"your_client_id_here\"\n",
    "os.environ[\"REDDIT_CLIENT_SECRET\"] = \"your_client_secret_here\"\n",
    "os.environ[\"REDDIT_USERNAME\"] = \"your_reddit_username\"\n",
    "os.environ[\"REDDIT_PASSWORD\"] = \"your_reddit_password\"\n",
    "os.environ[\"REDDIT_USER_AGENT\"] = \"longevity-agent by u/your_username\"\n",
    "\n",
    "# Persist to Google Drive (optional)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# os.environ[\"DATA_DIR\"] = \"/content/drive/MyDrive/longevity_agent/data\"\n",
    "\n",
    "print(\"✓ Credentials configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Ollama (Local LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ollama\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "# Pull model (this will take 5-10 minutes)\n",
    "!ollama pull llama3.2:3b\n",
    "\n",
    "print(\"✓ Ollama installed and model downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Collect Reddit Posts\n",
    "\n",
    "Fetches last 365 days of r/longevity posts (~5-10 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/01_collect.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract Claims\n",
    "\n",
    "Extracts longevity claims using LLM (~30-45 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/02_extract_claims.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check Evidence\n",
    "\n",
    "Verifies claims against PubMed (~45-60 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/03_evidence_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Preview Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Load latest results\n",
    "files = glob.glob(\"data/processed/claims_evidence_*.csv\")\n",
    "latest_file = max(files)\n",
    "df = pd.read_csv(latest_file)\n",
    "\n",
    "print(f\"✓ Loaded {len(df)} claims from {latest_file}\")\n",
    "print(f\"\\nEvidence distribution:\")\n",
    "print(df[\"evidence_level\"].value_counts())\n",
    "\n",
    "print(f\"\\nTop 10 topics:\")\n",
    "print(df[\"topic\"].value_counts().head(10))\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\nSample claims:\")\n",
    "df.head(10)[[\"claim\", \"topic\", \"evidence_level\", \"post_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download CSV\n",
    "files.download(latest_file)\n",
    "\n",
    "print(\"✓ Downloaded! Check your Downloads folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Optional: Generate Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate markdown report\n",
    "report = f\"\"\"# r/longevity Evidence Report\n",
    "\n",
    "Generated: {pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M\")}\n",
    "\n",
    "## Summary\n",
    "- Total claims: {len(df)}\n",
    "- Unique topics: {df['topic'].nunique()}\n",
    "- Strong evidence: {len(df[df['evidence_level'] == 'strong_support'])}\n",
    "\n",
    "## Evidence Distribution\n",
    "{df['evidence_level'].value_counts().to_markdown()}\n",
    "\n",
    "## Top 10 Most Upvoted Claims\n",
    "\"\"\"\n",
    "\n",
    "for idx, row in df.nlargest(10, 'post_score').iterrows():\n",
    "    report += f\"\\n### {row['claim']}\\n\"\n",
    "    report += f\"- Topic: {row['topic']}\\n\"\n",
    "    report += f\"- Evidence: {row['evidence_level']}\\n\"\n",
    "    report += f\"- Reddit Score: {row['post_score']}\\n\\n\"\n",
    "\n",
    "# Save report\n",
    "with open(\"longevity_report.md\", \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "files.download(\"longevity_report.md\")\n",
    "print(\"✓ Report generated and downloaded!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
